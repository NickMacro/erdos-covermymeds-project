{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fda823-3725-4e09-a44e-29369813d70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c3aaa-4beb-4e34-8655-194556b2ed3c",
   "metadata": {},
   "source": [
    "# Tasks\n",
    "- Build final logistic regression models for each problem\n",
    "- Save the models using `joblib`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845e63bd-7dbf-40c0-b1c8-588c99fd063c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_pipe():\n",
    "    encoder = OneHotEncoder(sparse=False, drop='first')\n",
    "    model = RandomForestClassifier(random_state=42)\n",
    "    pipe = Pipeline([('encoder', encoder),\n",
    "                     ('model', model)])\n",
    "    return pipe   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41e78c3-0ab0-425f-ac30-11d8f3fc4b4c",
   "metadata": {},
   "source": [
    "## Claim Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f34e1dca-b0e6-47a6-b68e-0728a33e335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_df = pd.read_csv('../data/processed/dim_claims_train.csv')\n",
    "\n",
    "claims_X = claims_df[['bin', 'drug']]\n",
    "claims_y = claims_df['pharmacy_claim_approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cfc6fe5-bd2c-4f6f-9767-a21c2b076d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./saved-models/random-forest-claim-approval.joblib']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claims_final_pipe = build_pipe()\n",
    "claims_final_pipe.fit(claims_X, claims_y)\n",
    "dump(claims_final_pipe, r'./saved-models/random-forest-claim-approval.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d9c48e9-48a4-400c-be06-518830425efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_test_df = pd.read_csv('../data/processed/dim_claims_test.csv')\n",
    "\n",
    "claims_X_test = claims_test_df[['bin', 'drug']]\n",
    "claims_y_test = claims_test_df['pharmacy_claim_approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1541be98-14c1-4154-bfd1-7bf2d393e313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.94\n",
      "Test Precision = 0.9\n",
      "Test Recall = 1.0\n",
      "Test ROC AUC = 0.92\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(claims_y_test, claims_final_pipe.predict(claims_X_test))\n",
    "test_precision = precision_score(claims_y_test, claims_final_pipe.predict(claims_X_test))\n",
    "test_recall = recall_score(claims_y_test, claims_final_pipe.predict(claims_X_test))\n",
    "test_roc_auc = roc_auc_score(claims_y_test, claims_final_pipe.predict_proba(claims_X_test)[:, 1])\n",
    "\n",
    "print(f'Test Accuracy = {round(test_accuracy, 2)}')\n",
    "print(f'Test Precision = {round(test_precision, 2)}')\n",
    "print(f'Test Recall = {round(test_recall, 2)}')\n",
    "print(f'Test ROC AUC = {round(test_roc_auc, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a82175-0085-4dc0-a97f-e4f1c9938289",
   "metadata": {},
   "source": [
    "## Reject Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32468699-4040-41fa-bf4c-064196f592e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_code_df = pd.read_csv('../data/processed/dim_claims_train.csv').fillna(0)\n",
    "reject_code_df.loc[:, 'reject_code'] = reject_code_df['reject_code'].astype(int)\n",
    "# only the rejected claims should be examined when determining reject code\n",
    "reject_code_df = reject_code_df.loc[reject_code_df['pharmacy_claim_approved'] == 0]\n",
    "\n",
    "reject_code_X = reject_code_df[['bin', 'drug']]\n",
    "reject_code_y = reject_code_df['reject_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ad3f03f-4ee5-479f-b063-5e69ec5e2713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./saved-models/random-forest-reject-code.joblib']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reject_code_final_pipe = build_pipe()\n",
    "reject_code_final_pipe.fit(reject_code_X, reject_code_y)\n",
    "dump(reject_code_final_pipe, r'./saved-models/random-forest-reject-code.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2bc3067-ebcc-4cc4-85a2-428f9c534d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "reject_code_test_df = pd.read_csv('../data/processed/dim_claims_test.csv').fillna(0)\n",
    "reject_code_test_df.loc[:, 'reject_code'] = reject_code_test_df['reject_code'].astype(int)\n",
    "# only the rejected claims should be examined when determining reject code\n",
    "reject_code_test_df = reject_code_test_df.loc[reject_code_test_df['pharmacy_claim_approved'] == 0]\n",
    "\n",
    "reject_code_X_test = reject_code_test_df[['bin', 'drug']]\n",
    "reject_code_y_test = reject_code_test_df['reject_code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d87c8788-9075-4e0c-8026-ba7476fb9f9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 1.0\n",
      "Test Precision = 1.0\n",
      "Test Recall = 1.0\n",
      "Test ROC AUC = 1.0\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(reject_code_y_test, reject_code_final_pipe.predict(reject_code_X_test))\n",
    "test_precision = precision_score(reject_code_y_test, reject_code_final_pipe.predict(reject_code_X_test), average='macro')\n",
    "test_recall = recall_score(reject_code_y_test, reject_code_final_pipe.predict(reject_code_X_test), average='macro')\n",
    "test_roc_auc = roc_auc_score(reject_code_y_test, reject_code_final_pipe.predict_proba(reject_code_X_test), average='macro', multi_class='ovo')\n",
    "\n",
    "print(f'Test Accuracy = {round(test_accuracy, 2)}')\n",
    "print(f'Test Precision = {round(test_precision, 2)}')\n",
    "print(f'Test Recall = {round(test_recall, 2)}')\n",
    "print(f'Test ROC AUC = {round(test_roc_auc, 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70bf8fb0-31ba-46ea-b5d9-eabe627a9f05",
   "metadata": {},
   "source": [
    "## PA Approval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74cbcfc6-5537-4a82-8a0c-4cbf26939be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_df = pd.read_csv('../data/processed/dim_claims_train.csv').fillna(0)\n",
    "claims_df.loc[:, 'reject_code'] = claims_df['reject_code'].astype(int)\n",
    "\n",
    "pa_df = pd.read_csv('../data/processed/dim_pa_train.csv')\n",
    "bridge_df = pd.read_csv('../data/processed/bridge_train.csv')\n",
    "\n",
    "combined_df = bridge_df.merge(claims_df, on='dim_claim_id').merge(pa_df, on='dim_pa_id')\n",
    "\n",
    "pa_X = combined_df[['bin', 'drug', 'correct_diagnosis', 'tried_and_failed', 'contraindication']]\n",
    "pa_y = combined_df['pa_approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "354deb80-4fff-42a2-9978-9d497389288d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./saved-models/random-forest-pa-approval.joblib']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_final_pipe = build_pipe()\n",
    "pa_final_pipe.fit(pa_X, pa_y)\n",
    "dump(pa_final_pipe, r'./saved-models/random-forest-pa-approval.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45ee24ef-fe19-4dbc-8b76-2eccfb56acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_test_df = pd.read_csv('../data/processed/dim_claims_test.csv').fillna(0)\n",
    "claims_test_df.loc[:, 'reject_code'] = claims_df['reject_code'].astype(int)\n",
    "\n",
    "pa_test_df = pd.read_csv('../data/processed/dim_pa_test.csv')\n",
    "bridge_test_df = pd.read_csv('../data/processed/bridge_test.csv')\n",
    "\n",
    "combined_test_df = bridge_test_df.merge(claims_test_df, on='dim_claim_id').merge(pa_test_df, on='dim_pa_id')\n",
    "\n",
    "pa_X_test = combined_test_df[['bin', 'drug', 'correct_diagnosis', 'tried_and_failed', 'contraindication']]\n",
    "pa_y_test = combined_test_df['pa_approved']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c61ea6eb-75e8-4180-8c2c-8783cc2425eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy = 0.81\n",
      "Test Precision = 0.83\n",
      "Test Recall = 0.94\n",
      "Test ROC AUC = 0.88\n"
     ]
    }
   ],
   "source": [
    "test_accuracy = accuracy_score(pa_y_test, pa_final_pipe.predict(pa_X_test))\n",
    "test_precision = precision_score(pa_y_test, pa_final_pipe.predict(pa_X_test))\n",
    "test_recall = recall_score(pa_y_test, pa_final_pipe.predict(pa_X_test))\n",
    "test_roc_auc = roc_auc_score(pa_y_test, pa_final_pipe.predict_proba(pa_X_test)[:, 1])\n",
    "\n",
    "print(f'Test Accuracy = {round(test_accuracy, 2)}')\n",
    "print(f'Test Precision = {round(test_precision, 2)}')\n",
    "print(f'Test Recall = {round(test_recall, 2)}')\n",
    "print(f'Test ROC AUC = {round(test_roc_auc, 2)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
