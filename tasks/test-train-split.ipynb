{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86774ead-32f8-4148-9451-d5cc0c1926f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836b9197-3b3c-4445-9210-2e069f1a8b7a",
   "metadata": {},
   "source": [
    "# Test Train Split\n",
    "## Bridge Split\n",
    "A 80:20 train/test split is applied to the data. This is achieved by performing a train_test split on the `bridge` using `train_test_split` from `sklearn`. The data is shuffled because the raw records are sorted. The other tables will be split by separating those tables using the unique IDs from the split `bridge`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afc001f1-2849-4474-ad51-0cc7c2a2f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bridge_df = pd.read_csv('../data/raw/bridge.csv')\n",
    "bridge_train, bridge_test = train_test_split(bridge_df, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "# index sorted for easier confirmation of filtering\n",
    "bridge_train = bridge_train.sort_index()\n",
    "bridge_test = bridge_test.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888781b0-cef3-40b9-9df7-ebca530bf24a",
   "metadata": {},
   "source": [
    "It is confirmed that the split was successful by comparing the combination of test and train data with the original pre-split data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39edac85-6f70-41c1-86ac-690a04c80685",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the combined data index need to be sorted because the dataframes must be aligned to use compare\n",
    "# empty DataFrame result indicates identical DataFrames\n",
    "bridge_train.append(bridge_test).sort_index().compare(bridge_df).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7808bfde-0007-4914-93ae-a9d0fa9e273b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=False and fillna('NA') are used to maintain the same structure as the raw data\n",
    "bridge_train.fillna('NA').to_csv('../data/processed/bridge_train.csv', index=False)\n",
    "bridge_test.fillna('NA').to_csv('../data/processed/bridge_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2dab8e-02bf-4b19-8e9e-1f8784f489f0",
   "metadata": {},
   "source": [
    "## Claims Split\n",
    "`dim_claim_id` is used to separate the `claims` test and train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2caf051e-cd67-4de1-b459-884067e90f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims_df = pd.read_csv('../data/raw/dim_claims.csv')\n",
    "claims_train = claims_df.loc[claims_df['dim_claim_id'].isin(bridge_train['dim_claim_id'])]\n",
    "claims_test = claims_df.loc[claims_df['dim_claim_id'].isin(bridge_test['dim_claim_id'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1cb855-451a-4c5a-ad15-bb41f8355d05",
   "metadata": {},
   "source": [
    "The unique IDs present in the `bridge` test and train splits identical to those in the `claims` test and train splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52cd9d6f-07f7-4cf1-927e-2ea693f74490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# compare the dim_claim_id values of the bridge and claims dataframes\n",
    "print(np.all(bridge_test['dim_claim_id'].values == claims_test['dim_claim_id'].values))\n",
    "print(np.all(bridge_train['dim_claim_id'].values == claims_train['dim_claim_id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d97de4f-afb0-4888-9fcf-542678abcc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=False and fillna('NA') are used to maintain the same structure as the raw data\n",
    "claims_train.fillna('NA').to_csv('../data/processed/dim_claims_train.csv', index=False)\n",
    "claims_test.fillna('NA').to_csv('../data/processed/dim_claims_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6684c304-1273-49fa-a749-4d221e0b521b",
   "metadata": {},
   "source": [
    "## PA Split\n",
    "`dim_pa_id` is used to separate the `pa` test and train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2f76aaa-2db0-4ae7-8cb0-e228c19a34be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "pa_df = pd.read_csv('../data/raw/dim_pa.csv')\n",
    "pa_train = pa_df.loc[pa_df['dim_pa_id'].isin(bridge_train['dim_pa_id'])]\n",
    "pa_test = pa_df.loc[pa_df['dim_pa_id'].isin(bridge_test['dim_pa_id'])]\n",
    "\n",
    "# compare the dim_pa_id values of the bridge and pa dataframes\n",
    "# dropna is required for the bridge dataframes because nan is \n",
    "# provided if the claim does not have a pa\n",
    "print(np.all(bridge_test['dim_pa_id'].dropna().values == pa_test['dim_pa_id'].values))\n",
    "print(np.all(bridge_train['dim_pa_id'].dropna().values == pa_train['dim_pa_id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13396deb-18d5-47ed-9b79-f9f5221e0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=False and fillna('NA') are used to maintain the same structure as the raw data\n",
    "pa_train.fillna('NA').to_csv('../data/processed/dim_pa_train.csv', index=False)\n",
    "pa_test.fillna('NA').to_csv('../data/processed/dim_pa_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab62edb-63b5-4bfc-b0ac-4b064746b5bb",
   "metadata": {},
   "source": [
    "## Date Split\n",
    "`dim_date_id` is used to separate the `date` test and train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9fb6f3b-98a7-4da2-bbe9-914f23ebea68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "date_df = pd.read_csv('../data/raw/dim_date.csv')\n",
    "date_train = date_df.loc[date_df['dim_date_id'].isin(bridge_train['dim_date_id'])]\n",
    "date_test = date_df.loc[date_df['dim_date_id'].isin(bridge_test['dim_date_id'])]\n",
    "\n",
    "# compare the dim_date_id values of the bridge and pa dataframes\n",
    "# unique is required for the bridge dataframes because multiple claims\n",
    "# contain the same date id\n",
    "print(np.all(bridge_test['dim_date_id'].unique() == date_test['dim_date_id'].values))\n",
    "print(np.all(bridge_train['dim_date_id'].unique() == date_train['dim_date_id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd2ae74-351e-4ea3-8cdb-74fc672db39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index=False and fillna('NA') are used to maintain the same structure as the raw data\n",
    "date_train.fillna('NA').to_csv('../data/processed/dim_date_train.csv', index=False)\n",
    "date_test.fillna('NA').to_csv('../data/processed/dim_date_test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
